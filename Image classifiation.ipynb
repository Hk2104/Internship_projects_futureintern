{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "IMAGE CLASSIFICATION"
      ],
      "metadata": {
        "id": "J4is5ClPreuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A deep learning model using the CIFAR-10 dataset to classify images into 10 distinct categories, including objects like airplanes, cars, and animals. Prepare the dataset by standardizing image sizes and normalizing pixel values. Select a convolutional neural network (CNN) architecture like ResNet or VGG for its effectiveness in image classification tasks. Train the model on labeled images to learn features that differentiate between different classes. Evaluate the model's accuracy and performance metrics on a separate test set to validate its capability in accurately categorizing images across varied classes."
      ],
      "metadata": {
        "id": "-djNhEF8riK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a step-by-step guide to building a deep learning model using the CIFAR-10 dataset to classify images into 10 distinct categories:"
      ],
      "metadata": {
        "id": "xXFir3RKrp3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Import necessary libraries and load the CIFAR-10 dataset"
      ],
      "metadata": {
        "id": "7x29hh_9rqq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbeVci7Rrsvy",
        "outputId": "8f793020-504d-4f65-fd01-d678e93f5d55"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Preprocess the dataset"
      ],
      "metadata": {
        "id": "8HzmtQJpr5rJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardize image sizes: The CIFAR-10 dataset already has images of size 32x32,\n",
        "so no resizing is needed.\n",
        "\n",
        "Normalize pixel values: Normalize the pixel values to be between 0 and 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dk9iUcgMr9Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize pixel values\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "bHOAr2-isK1o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Convert class labels to categorical"
      ],
      "metadata": {
        "id": "qCIvq0ZYsPTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the class labels to categorical using to_categorical from Keras."
      ],
      "metadata": {
        "id": "jdNl_-S0sS2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert class labels to categorical\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "2a7qok7usVNp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Split the dataset into training and validation sets"
      ],
      "metadata": {
        "id": "9k8lx9THsZjA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training and validation sets using train_test_split from Scikit-learn."
      ],
      "metadata": {
        "id": "INMalvBVsaV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "_jd-adm_scsV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Define the CNN architecture"
      ],
      "metadata": {
        "id": "edQV8C8vsiF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select a CNN architecture like ResNet or VGG. For this example, we'll use a simple CNN architecture with two convolutional layers and two fully connected layers."
      ],
      "metadata": {
        "id": "xnT0jhgrsjY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "lPQhOwX-smyg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Compile the model"
      ],
      "metadata": {
        "id": "w5o6TVWosr_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model with a suitable optimizer and loss function."
      ],
      "metadata": {
        "id": "KxiHAx24sslX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Oos-uK37su76"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train the model"
      ],
      "metadata": {
        "id": "ONVRNFjDs1Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model on the training set."
      ],
      "metadata": {
        "id": "giruWTqBs1sf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk7ILj_Ws35y",
        "outputId": "ab27ad9c-9011-4dd5-fb23-127a942cbd34"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "313/313 [==============================] - 50s 155ms/step - loss: 1.6008 - accuracy: 0.4248 - val_loss: 1.3997 - val_accuracy: 0.4993\n",
            "Epoch 2/10\n",
            "313/313 [==============================] - 45s 144ms/step - loss: 1.2693 - accuracy: 0.5530 - val_loss: 1.1792 - val_accuracy: 0.5792\n",
            "Epoch 3/10\n",
            "313/313 [==============================] - 46s 147ms/step - loss: 1.1173 - accuracy: 0.6096 - val_loss: 1.1198 - val_accuracy: 0.6087\n",
            "Epoch 4/10\n",
            "313/313 [==============================] - 47s 150ms/step - loss: 1.0281 - accuracy: 0.6449 - val_loss: 1.0084 - val_accuracy: 0.6482\n",
            "Epoch 5/10\n",
            "313/313 [==============================] - 49s 156ms/step - loss: 0.9452 - accuracy: 0.6730 - val_loss: 0.9526 - val_accuracy: 0.6734\n",
            "Epoch 6/10\n",
            "313/313 [==============================] - 50s 159ms/step - loss: 0.8930 - accuracy: 0.6905 - val_loss: 0.9509 - val_accuracy: 0.6694\n",
            "Epoch 7/10\n",
            "313/313 [==============================] - 46s 146ms/step - loss: 0.8437 - accuracy: 0.7086 - val_loss: 0.9479 - val_accuracy: 0.6714\n",
            "Epoch 8/10\n",
            "313/313 [==============================] - 49s 156ms/step - loss: 0.7941 - accuracy: 0.7257 - val_loss: 0.9364 - val_accuracy: 0.6754\n",
            "Epoch 9/10\n",
            "313/313 [==============================] - 46s 147ms/step - loss: 0.7491 - accuracy: 0.7444 - val_loss: 0.9611 - val_accuracy: 0.6678\n",
            "Epoch 10/10\n",
            "313/313 [==============================] - 48s 155ms/step - loss: 0.7070 - accuracy: 0.7562 - val_loss: 0.9233 - val_accuracy: 0.6828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Evaluate the model"
      ],
      "metadata": {
        "id": "Se3OxwgVu4YJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the test set."
      ],
      "metadata": {
        "id": "84vpaWh5u5BB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(x_test)\n",
        "y_pred_class = tf.argmax(y_pred, axis=1)\n",
        "y_test_class = tf.argmax(y_test, axis=1)\n",
        "\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "print(f'Test accuracy: {accuracy:.3f}')\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_class, y_pred_class))\n",
        "\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test_class, y_pred_class))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctrNSl0mu7YZ",
        "outputId": "7c6235e3-02e2-44b0-9a2a-83ccb987c1fa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 22ms/step\n",
            "Test accuracy: 0.686\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.77      0.73      1000\n",
            "           1       0.75      0.86      0.80      1000\n",
            "           2       0.56      0.60      0.58      1000\n",
            "           3       0.52      0.52      0.52      1000\n",
            "           4       0.67      0.57      0.62      1000\n",
            "           5       0.63      0.57      0.60      1000\n",
            "           6       0.65      0.86      0.74      1000\n",
            "           7       0.76      0.72      0.74      1000\n",
            "           8       0.82      0.76      0.79      1000\n",
            "           9       0.89      0.64      0.74      1000\n",
            "\n",
            "    accuracy                           0.69     10000\n",
            "   macro avg       0.69      0.69      0.69     10000\n",
            "weighted avg       0.69      0.69      0.69     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[768  25  67  26  10   9  15   3  61  16]\n",
            " [ 31 857   9  18   3   3  22   4  21  32]\n",
            " [ 55   9 601  56  78  66  87  34  10   4]\n",
            " [ 24  14  84 522  49 139 121  30  11   6]\n",
            " [ 31   9 107  71 571  19 108  71  13   0]\n",
            " [ 23   6  73 175  41 570  55  50   7   0]\n",
            " [  6   4  53  41  18  11 859   3   3   2]\n",
            " [ 27   6  50  38  62  69  20 720   3   5]\n",
            " [102  55  17  16   5   9  15   9 756  16]\n",
            " [ 47 155  14  32  10  10  29  25  40 638]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This should give you a basic image classification model using the CIFAR-10 dataset. You can experiment with different architectures, hyperparameters, and techniques to improve the model's performance."
      ],
      "metadata": {
        "id": "jY0oNDYgvB34"
      }
    }
  ]
}